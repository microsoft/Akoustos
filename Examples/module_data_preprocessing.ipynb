{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "welcome-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla V100-SXM2-32GB, compute capability 7.0\n"
     ]
    }
   ],
   "source": [
    "## check availability of GPU (nvidia-smi)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os \n",
    "import glob\n",
    "\n",
    "current_dir = \"/mnt/akoustos/\"\n",
    "\n",
    "data_dir = current_dir + \"Data/\"\n",
    "labeled_data_dir = data_dir + 'Labeled_Data/'\n",
    "audio_dir = data_dir + \"Raw_Audio/\"\n",
    "\n",
    "spectrogram_dir = data_dir + \"Extracted_Spectrogram/\"\n",
    "if not os.path.exists(spectrogram_dir):\n",
    "    os.makedirs(spectrogram_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-theorem",
   "metadata": {},
   "source": [
    "### module: Upload audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brave-roller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio files: 37414\n",
      "Time spent to upload audio files:  17.348192 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.load_data import Load_Data\n",
    "audio_filenames = Load_Data.audio_filenames(directory = audio_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-crash",
   "metadata": {},
   "source": [
    "### module: Upload labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "urban-niagara",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category  Count  Percentage\n",
      "0        14    500       21.83\n",
      "1        25    500       21.83\n",
      "2      2662    407       17.77\n",
      "3      4949    501       21.88\n",
      "4      5620    382       16.68\n",
      "Time spent to upload labeled data:  0.161514 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.load_data import Load_Data\n",
    "labeled_data = Load_Data.labeled_data(labeled_data_dir = labeled_data_dir, audio_dir = audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-finland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-bargain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "industrial-distribution",
   "metadata": {},
   "source": [
    "### module: Sound Event Detection \n",
    "#### this module needs \"audio_filenames\" and \"labeled_data\" from previous two modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "higher-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Category  Count  Percentage\n",
      "0              14    500       17.44\n",
      "1              25    500       17.44\n",
      "2            2662    407       14.20\n",
      "3            4949    501       17.47\n",
      "4            5620    382       13.32\n",
      "5  No Sound Event    577       20.13\n",
      "Time spent to preprocess data:  800.842548 seconds\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from statistics import median\n",
    "import cv2\n",
    "import warnings\n",
    "from math import ceil, floor\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from src.audio import Audio\n",
    "from src.preprocessing import speechproc\n",
    "from src.preprocessing import spectrogating\n",
    "from copy import deepcopy\n",
    "from scipy.signal import lfilter\n",
    "    \n",
    "\n",
    "def sound_event_detection_for_single_audio_file(annotation_base_audio_filename):\n",
    "    df = pd.DataFrame(columns = list(labeled_data))\n",
    "    matching_audio_filename = [audio_filename for audio_filename in audio_filenames if os.path.basename(audio_filename) == annotation_base_audio_filename]\n",
    "    audio = Audio.load(matching_audio_filename.pop())\n",
    "    \n",
    "    ## sound event detection\n",
    "    noise = audio.samples[0:1*audio.sample_rate]\n",
    "    x_dn = spectrogating.removeNoise(audio_clip=audio.samples, \n",
    "                                     noise_clip=noise,\n",
    "                                     n_grad_freq=2,\n",
    "                                     n_grad_time=4,\n",
    "                                     n_fft=2048,\n",
    "                                     win_length=2048,\n",
    "                                     hop_length=512,\n",
    "                                     n_std_thresh=2.5,\n",
    "                                     prop_decrease=1.0,\n",
    "                                     verbose=False,\n",
    "                                     visual=False)\n",
    "\n",
    "    winlen, ovrlen, pre_coef, nfilter, nftt = 0.025, 0.01, 0.97, 20, 2048\n",
    "    ftThres = 0.4\n",
    "    vadThres = 0.2\n",
    "    opts = 1\n",
    "    ft, flen, fsh10, nfr10 = speechproc.sflux(x_dn, audio.sample_rate, winlen, ovrlen, nftt)\n",
    "    # --spectral flatness --\n",
    "    pv01 = np.zeros(nfr10)\n",
    "    pv01[np.less_equal(ft, ftThres)] = 1 \n",
    "    pitch = deepcopy(ft)\n",
    "    pvblk = speechproc.pitchblockdetect(pv01, pitch, nfr10, opts)\n",
    "    # --filtering--\n",
    "    ENERGYFLOOR = np.exp(-50)\n",
    "    b = np.array([0.9770,   -0.9770])\n",
    "    a = np.array([0.3,   -0.3])\n",
    "    fdata = lfilter(b, a, x_dn, axis=0)\n",
    "    vad_seg = speechproc.snre_vad(fdata, nfr10, flen, fsh10, ENERGYFLOOR, pv01, pvblk, vadThres)  \n",
    "    no_events_starttime = [0] + [i / len(vad_seg) * audio.duration() for i in range(len(vad_seg)) if vad_seg[i] == 0 and vad_seg[i-1] == 1]\n",
    "    no_events_endtime = [i / len(vad_seg) * audio.duration() for i in range(len(vad_seg)) if vad_seg[i] == 1 and vad_seg[i-1] == 0] + [audio.duration()]\n",
    "    for start, end in zip(no_events_starttime, no_events_endtime):\n",
    "        new_row = {'Begin Time (s)': start,\n",
    "                   'End Time (s)': end,\n",
    "                   'Low Freq (Hz)': 0,\n",
    "                   'High Freq (Hz)': 0,\n",
    "                   'Begin File': annotation_base_audio_filename,\n",
    "                   'Category': 'No Sound Event'}\n",
    "        df = df.append(new_row, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "begin = datetime.now()\n",
    "\n",
    "annotation_base_audio_filenames = list(labeled_data['Begin File'].unique())\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "with Pool(processes=num_cores) as pool:\n",
    "    df_list = pool.map(sound_event_detection_for_single_audio_file, annotation_base_audio_filenames)\n",
    "    no_sound_event_data = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "no_sound_event_data['duration'] = no_sound_event_data['End Time (s)'] - no_sound_event_data['Begin Time (s)'] \n",
    "no_sound_event_data = no_sound_event_data.sort_values(by='duration',ascending=False)[: len(labeled_data) // len(labeled_data.Category.unique())]\n",
    "no_sound_event_data = no_sound_event_data.drop(['duration'], axis = 1)\n",
    " \n",
    "\n",
    "labeled_data = labeled_data.append(no_sound_event_data, ignore_index=True)\n",
    "summary = labeled_data.groupby(['Category']).size().reset_index(name='Count')\n",
    "summary['Percentage'] = round(100 * summary['Count']  / summary['Count'].sum(), 2)\n",
    "print(summary)\n",
    "        \n",
    "end = datetime.now()\n",
    "print('Time spent to preprocess data: ', (end - begin).total_seconds(), 'seconds')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-vocabulary",
   "metadata": {},
   "source": [
    "### module: Generate spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "senior-pension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent to generate spectrograms with parallelization:  218.535261 seconds\n",
      "Total number of spectrograms produced: 2821\n"
     ]
    }
   ],
   "source": [
    "from src.spectrogram import Spectrogram\n",
    "Spectrogram.clear_space(spectrogram_dir)  ## if don't want to keep previously generated spectrograms, clear space\n",
    "Spectrogram.generate_spectrograms_parallel(spectrogram_duration = 4, \n",
    "                                           labeled_data = labeled_data, \n",
    "                                           audio_filenames = audio_filenames, \n",
    "                                           save_to_dir = spectrogram_dir,\n",
    "                                           axis=False, \n",
    "                                           sr = 22050, \n",
    "                                           hop_length=512, \n",
    "                                           fmin=None, \n",
    "                                           fmax=None, \n",
    "                                           x_axis='time', \n",
    "                                           y_axis='linear', \n",
    "                                           cmap ='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "informative-connectivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of valid spectrograms: 2821\n",
      "shape of vector for valid spectrograms: (224, 224, 3)\n",
      "Time spent to load spectrograms as array:  417.726772 seconds\n"
     ]
    }
   ],
   "source": [
    "from src.load_data import Load_Data\n",
    "specctrogram_vector, spectrogram_filenames = Load_Data.load_spectrograms(directory=spectrogram_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-stack",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
